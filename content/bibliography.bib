@article{Batta2015,
abstract = {The value of in vivo reflectance confocal microscopy (RCM) as a noninvasive adjunctive tool in dermatology has steadily advanced since its inception. With RCM, dermatologists can view horizontal sections of lesions in a resolution comparable to histology, observe dynamic processes in living skin, and monitor lesion evolution longitudinally. This article will compare RCM to dermoscopy and histology, review the general principles of the microscope, describe the findings seen on confocal images, and discuss the clinical applications of this noninvasive tool. Additionally, we describe a telepathology network dedicated to the transfer of confocal images to remote dermatopathologists for interpretation. Finally, we will discuss the adoption of RCM and the telepathology network in clinical practice.},
author = {Batta, Mari M. and Kessler, Stephen E. and White, Peter F. and Zhu, Weijian and Fox, Christi Alessi},
doi = {10.1016/S0040-6090(02)00980-X},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Cutis/2015{\_}Reflectance confocal microscopy An overview of technology and advances in telepathology.pdf:pdf},
issn = {00114162},
journal = {Cutis},
number = {5},
pages = {E39--E46},
pmid = {26057520},
title = {{Reflectance confocal microscopy: An overview of technology and advances in telepathology}},
volume = {95},
year = {2015}
}
@misc{chollet2015keras,
author = {Chollet, Fran{\c{c}}ois and Others},
publisher = {GitHub},
title = {{Keras}},
url = {https://github.com/fchollet/keras},
year = {2015}
}
@article{coelho2012mahotas,
abstract = {Mahotas is a computer vision library for Python. It contains traditional image processing functionality such as filtering and morphological operations as well as more modern computer vision functions for feature computation, including interest point detection and local descriptors. The interface is in Python, a dynamic programming language, which is very appropriate for fast development, but the algorithms are implemented in C++ and are tuned for speed. The library is designed to fit in with the scientific software ecosystem in this language and can leverage the existing infrastructure developed in that language. Mahotas is released under a liberal open source license (MIT License) and is available from (http://github.com/luispedro/mahotas) and from the Python Package Index (http://pypi.python.org/pypi/mahotas).},
archivePrefix = {arXiv},
arxivId = {1211.4907},
author = {Coelho, Luis Pedro},
doi = {10.5334/jors.ac},
eprint = {1211.4907},
issn = {2049-9647},
journal = {arXiv preprint arXiv:1211.4907},
pmid = {25365147},
title = {{Mahotas: Open source software for scriptable computer vision}},
url = {https://arxiv.org/pdf/1211.4907.pdf},
year = {2012}
}
@inproceedings{Deng2008,
abstract = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called {\&}{\#}x201C;ImageNet{\&}{\#}x201D;, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500-1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
author = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2009.5206848},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/2009 IEEE Conference on Computer Vision and Pattern Recognition/2009{\_}ImageNet A large-scale hierarchical image database.pdf:pdf},
isbn = {978-1-4244-3992-8},
issn = {1063-6919},
number = {19},
pages = {248--255},
pmid = {18332136},
title = {{ImageNet: A large-scale hierarchical image database}},
volume = {283},
year = {2009}
}
@article{Freeman2018,
abstract = {We report development of a low-cost smartphone confocal microscope and its first demonstration of in vivo human skin imaging. The smartphone confocal microscope uses a slit aperture and diffraction grating to conduct two-dimensional confocal imaging without using any beam scanning devices. Lateral and axial resolutions of the smartphone confocal microscope were measured as 2 and 5 µm, respectively. In vivo confocal images of human skin revealed characteristic cellular structures, including spinous and basal keratinocytes and papillary dermis. Results suggest that the smartphone confocal microscope has a potential to examine cellular details in vivo and may help disease diagnosis in resource-poor settings, where conducting standard histopathologic analysis is challenging.},
author = {Freeman, Esther E. and Semeere, Aggrey and Osman, Hany and Peterson, Gary and Rajadhyaksha, Milind and Gonz{\'{a}}lez, Salvador and Martin, Jeffery N. and Anderson, R. Rox and Tearney, Guillermo J. and Kang, Dongkyun},
doi = {10.1364/BOE.9.001906},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Biomedical Optics Express/2018{\_}Smartphone confocal microscopy for imaging cellular structures in human skin in vivo.pdf:pdf},
isbn = {2156-7085 (Print) 2156-7085},
issn = {2156-7085},
journal = {Biomedical Optics Express},
number = {4},
pages = {1906--1915},
pmid = {29675328},
title = {{Smartphone confocal microscopy for imaging cellular structures in human skin in vivo}},
url = {https://www.osapublishing.org/abstract.cfm?URI=boe-9-4-1906},
volume = {9},
year = {2018}
}
@article{Haroon2017,
abstract = {Biopsy and histologic evaluation have been the gold standard to diagnose skin tumors. Reflectance confocal microcopy (RCM) is a noninvasive, innovative diagnostic technique that enables visualization of different skin layers at an almost histologic resolution. RCM has been proven beneficial in management of various cutaneous lesions. This article highlights the clinical significance and future of RCM to diagnose common skin cancers. However, RCM cannot replace currently standard histopathologic diagnosis. More studies are required to better compare the sensitivity and specificity of skin cancer diagnosis using RCM.},
author = {Haroon, Attiya and Shafi, Shahram and Rao, Babar K.},
doi = {10.1016/j.det.2017.06.007},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Dermatologic Clinics/2017{\_}Using Reflectance Confocal Microscopy in Skin Cancer Diagnosis.pdf:pdf},
isbn = {9780323546621},
issn = {15580520},
journal = {Dermatologic Clinics},
keywords = {Melanocytic skin cancer,Nonmelanocytic skin cancer,Reflectance confocal microscopy},
number = {4},
pages = {457--464},
pmid = {28886802},
title = {{Using Reflectance Confocal Microscopy in Skin Cancer Diagnosis}},
volume = {35},
year = {2017}
}
@article{Kolm2012,
author = {Kolm, Isabel and Braun, Ralph P.},
doi = {10.1007/978-3-642-21997-9_2},
isbn = {9783642219979},
journal = {Reflectance Confocal Microscopy for Skin Diseases},
pages = {7--10},
title = {{How reflectance confocal microscopy works}},
year = {2012}
}
@article{LeGal2011,
author = {{Le Gal}, Fr{\'{e}}d{\'{e}}rique-Anne and Toutous-Trellu, Laurence and Kaya, G{\"{u}}rkan and Salomon, Denis},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Revue M{\'{e}}dicale Suisse/2011{\_}Lentigo maligna un m{\'{e}}lanome particulier.pdf:pdf},
journal = {Revue M{\'{e}}dicale Suisse},
pages = {765--71},
title = {{Lentigo maligna : un m{\'{e}}lanome particulier}},
volume = {7},
year = {2011}
}
@misc{lee2006pywavelets,
abstract = {PyWavelet Documentation},
author = {Lee, G and Gommers, R and Wasilewski, F and Wohlfahrt, K and O'Leary, A and Nahrstaedt, H and Contributors},
pages = {1--2},
title = {{PyWavelets - Wavelet Transforms in Python}},
url = {https://github.com/PyWavelets/pywt},
year = {2006}
}
@article{Litjens2017,
abstract = {Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research.},
archivePrefix = {arXiv},
arxivId = {1702.05747},
author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen A.W.M. and van Ginneken, Bram and S{\'{a}}nchez, Clara I.},
doi = {10.1016/j.media.2017.07.005},
eprint = {1702.05747},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Medical Image Analysis/2017{\_}A survey on deep learning in medical image analysis.pdf:pdf},
isbn = {978-1-5386-3220-8},
issn = {13618423},
journal = {Medical Image Analysis},
keywords = {Convolutional neural networks,Deep learning,Medical imaging,Survey},
number = {December 2012},
pages = {60--88},
pmid = {28778026},
publisher = {Elsevier B.V.},
title = {{A survey on deep learning in medical image analysis}},
volume = {42},
year = {2017}
}
@article{Wiltgen2008,
abstract = {OBJECTIVES: Confocal laser scanning microscopy (CLSM) is used for quick medical checkups. The aim of this study is to check the discrimination power of texture features for the automatic identification of diagnostic significant regions in CLSM views of skin lesions. METHODS: In tissue counter analysis (TCA) the images are dissected in equal square elements, where different classes of features are calculated out. Features defined in the spatial domain are based on histogram (grey level distribution) and co-occurrence matrix (grey level combinations). The features defined in the frequency domain are based on spectral properties of the wavelet Daubechie 4 transform (texture exploration at different scales) and the Fourier transform (global texture properties are localized in the spectrum). Hundred cases of benign common nevi and malignant melanoma were used as the study set. Classification was done with CART (Classification and Regression Trees) analysis which splits the set of square elements into homogenous terminal nodes and generates a set of splitting rules. RESULTS: Features based on the wavelet transform provide the best results with 96.0{\%} of correctly classified elements from benign common nevi and 97.0{\%} from malignant melanoma. The classification results are relocated to the images by use of the splitting rules as diagnostic aid. The discriminated square elements are highlighted in the images, showing tissue with features in good accordance with typical diagnostic CLSM features. CONCLUSION: Square elements with more than 80{\%} of discrimination power enable the identification of diagnostic highly significant parts in confocal microscopic views of malignant melanoma.},
author = {Wiltgen, Marco and Gerger, A. and Wagner, C. and Smolle, J.},
doi = {10.3414/ME0463},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Methods of Information in Medicine/2008{\_}Automatic identification of diagnostic significant regions in confocal laser scanning microscopy of melanocytic skin tumors.pdf:pdf},
issn = {00261270},
journal = {Methods of Information in Medicine},
keywords = {Computer-assisted diagnosis,Confocal laser scanning microscopy,Medical image processing,Tissue counter analysis},
number = {1},
pages = {14--25},
pmid = {18213424},
title = {{Automatic identification of diagnostic significant regions in confocal laser scanning microscopy of melanocytic skin tumors}},
volume = {47},
year = {2008}
}
@article{Halimi2017a,
abstract = {The matrix-completion problem has attracted a lot of attention, largely as a result of the celebrated Netflix competition. Two popular approaches for solving the problem are nuclear-norm-regularized matrix approximation (Candes and Tao, 2009, Mazumder, Hastie and Tibshirani, 2010), and maximum-margin matrix factorization (Srebro, Rennie and Jaakkola, 2005). These two procedures are in some cases solving equivalent problems, but with quite different algorithms. In this article we bring the two approaches together, leading to an efficient algorithm for large matrix factorization and completion that outperforms both of these. We develop a software package "softImpute" in R for implementing our approaches, and a distributed version for very large matrices using the "Spark" cluster programming environment.},
archivePrefix = {arXiv},
arxivId = {1410.2596},
author = {Halimi, Abdelghafour and Batatia, Hadj and {Le Digabel}, Jimmy and Josse, Gwendal and Tourneret, Jean Yves},
doi = {10.1364/boe.8.005450},
eprint = {1410.2596},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Biomedical Optics Express/2017{\_}Wavelet-based statistical classification of skin images acquired with reflectance confocal microscopy.pdf:pdf},
issn = {2156-7085},
journal = {Biomedical Optics Express},
keywords = {Image processing - Image analysis - Wavelets - Mic},
number = {12},
pages = {5450--5467},
pmid = {29296480},
publisher = {The Optical Society},
title = {{Wavelet-based statistical classification of skin images acquired with reflectance confocal microscopy}},
url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5745095/pdf/boe-8-12-5450.pdf},
volume = {8},
year = {2017}
}
@inproceedings{Szegedy2015,
abstract = {Convolutional networks are at the core of most state-of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we explore ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21.2{\%} top-1 and 5.6{\%} top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3.5{\%} top-5 error on the validation set (3.6{\%} error on the test set) and 17.3{\%} top-1 error on the validation set.},
archivePrefix = {arXiv},
arxivId = {1512.00567},
author = {Szegedy, Christian and Vanhoucke, Vincent and Ioffe, Sergey and Shlens, Jonathon and Wojna, Zbigniew},
booktitle = {Proceedings of the IEEE conference on computer vision and pattern recognition},
doi = {10.1109/CVPR.2016.308},
eprint = {1512.00567},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Proceedings of the IEEE conference on computer vision and pattern recognition/2015{\_}Rethinking the Inception Architecture for Computer Vision.pdf:pdf},
isbn = {978-1-4673-8851-1},
issn = {08866236},
pages = {2818--2826},
pmid = {8190083},
title = {{Rethinking the Inception Architecture for Computer Vision}},
url = {http://arxiv.org/abs/1512.00567},
year = {2015}
}
@article{Iyatomi2010,
abstract = {In this paper, we present a classification method of dermoscopy images between melanocytic skin lesions (MSLs) and non-melanocytic skin lesions (NoMSLs). The motivation of this research is to develop a pre-processor of an automated melanoma screening system. Since NoMSLs have a wide variety of shapes and their border is often ambiguous, we developed a new tumor area extraction algorithm to account for these difficulties. We confirmed that this algorithm is capable of handling different dermoscopy images not only those of NoMSLs but also MSLs as well. We determined the tumor area from the image using this new algorithm, calculated a total 428 features from each image, and built a linear classifier. We found only two image features, "the skewness of bright region in the tumor along its major axis" and "the difference between the average intensity in the peripheral part of the tumor and that in the normal skin area using the blue channel" were very efficient at classifying NoMSLs and MSLs. The detection accuracy of MSLs by our classifier using only the above mentioned image feature has a sensitivity of 98.0{\%} and a specificity of 86.6{\%} in a set of 107 non-melanocytic and 548 melanocytic dermoscopy images using a cross-validation test.},
author = {Iyatomi, Hitoshi and Norton, Kerri Ann and Celebi, M. Emre and Schaefer, Gerald and Tanaka, Masaru and Ogawa, Koichi},
doi = {10.1109/IEMBS.2010.5626500},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10/2010{\_}Classification of melanocytic skin lesions from non-melanocytic lesions.pdf:pdf},
isbn = {9781424441235},
issn = {1557-170X},
journal = {2010 Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBC'10},
keywords = {Computer-aided diagnosis,Dermoscopy,Melanoma},
pages = {5407--5410},
pmid = {21096271},
title = {{Classification of melanocytic skin lesions from non-melanocytic lesions}},
year = {2010}
}
@article{pedregosa2011scikit,
abstract = {Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.sourceforge.net.},
author = {Pedregosa, Fabian and Varoquaux, Ga{\"{e}}l and Gramfort, Alexandre and Michel, Vincent and Thirion, Bertrand and Grisel, Olivier and Blondel, Mathieu and Prettenhofer, Peter and Weiss, Ron and Dubourg, Vincent and Others},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of machine learning research/2011{\_}Scikit-learn Machine Learning in Python.pdf:pdf},
issn = {1532-4435},
journal = {Journal of machine learning research},
number = {Oct},
pages = {2825--2830},
title = {{Scikit-learn: Machine Learning in Python}},
url = {http://dl.acm.org/citation.cfm?id=1953048.2078195},
volume = {12},
year = {2011}
}
@article{Rastgoo2015,
abstract = {Dysplastic classification.Malignant melanoma causes the majority of deaths related to skin cancer. Nevertheless, it is the most treatable one, depending on its early diagnosis. The early prognosis is a challenging task for both clinicians and dermatologist, due to the characteristic similarities of melanoma with other skin lesions such as dysplastic nevi. In the past decades, several computerized lesion analysis algorithms have been proposed by the research community for detection of melanoma. These algorithms mostly focus on differentiating melanoma from benign lesions and few have considered the case of melanoma against dysplastic nevi. In this paper, we consider the most challenging task and propose an automatic framework for differentiation of melanoma from dysplastic nevi. The proposed framework also considers combination and comparison of several texture features beside the well used colour and shape features based on "ABCD" clinical rule in the literature. Focusing on dermoscopy images, we evaluate the performance of the framework using two feature extraction approaches, global and local (bag of words) and three classifiers such as support vector machine, gradient boosting and random forest. Our evaluation revealed the potential of texture features and random forest as an almost independent classifier. Using texture features and random forest for differentiation of melanoma and dysplastic nevi, the framework achieved the highest sensitivity of 98{\%} and specificity of 70{\%}.},
author = {Rastgoo, Mojdeh and Garcia, Rafael and Morel, Olivier and Marzani, Franck},
doi = {10.1016/j.compmedimag.2015.02.011},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Computerized Medical Imaging and Graphics/2015{\_}Automatic differentiation of melanoma from dysplastic nevi.pdf:pdf},
isbn = {0895-6111},
issn = {18790771},
journal = {Computerized Medical Imaging and Graphics},
keywords = {Classification,Colour,Dermoscopy imaging,Dysplastic,Machine learning,Melanoma,Shape features,Texture},
pages = {44--52},
pmid = {25797605},
title = {{Automatic differentiation of melanoma from dysplastic nevi}},
volume = {43},
year = {2015}
}
@article{Sinz2017,
abstract = {Background Nonpigmented skin cancer is common, and diagnosis with the unaided eye is error prone. Objective To investigate whether dermatoscopy improves the diagnostic accuracy for nonpigmented (amelanotic) cutaneous neoplasms. Methods We collected a sample of 2072 benign and malignant neoplastic lesions and inflammatory conditions and presented close-up images taken with and without dermatoscopy to 95 examiners with different levels of experience. Results The area under the curve was significantly higher with than without dermatoscopy (0.68 vs 0.64, P {\textless}.001). Among 51 possible diagnoses, the correct diagnosis was selected in 33.1{\%} of cases with and 26.4{\%} of cases without dermatoscopy (P {\textless}.001). For experts, the frequencies of correct specific diagnoses of a malignant lesion improved from 40.2{\%} without to 51.3{\%} with dermatoscopy. For all malignant neoplasms combined, the frequencies of appropriate management strategies increased from 78.1{\%} without to 82.5{\%} with dermatoscopy. Limitations The study deviated from a real-life clinical setting and was potentially affected by verification and selection bias. Conclusions Dermatoscopy improves the diagnosis and management of nonpigmented skin cancer and should be used as an adjunct to examination with the unaided eye.},
author = {Sinz, Christoph and Tschandl, Philipp and Rosendahl, Cliff and Akay, Bengu Nisa and Argenziano, Giuseppe and Blum, Andreas and Braun, Ralph P. and Cabo, Horacio and Gourhant, Jean Yves and Kreusch, Juergen and Lallas, Aimilios and Lapins, Jan and Marghoob, Ashfaq A. and Menzies, Scott W. and Paoli, John and Rabinovitz, Harold S. and Rinner, Christoph and Scope, Alon and Soyer, H. Peter and Thomas, Luc and Zalaudek, Iris and Kittler, Harald},
doi = {10.1016/j.jaad.2017.07.022},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of the American Academy of Dermatology/2017{\_}Accuracy of dermatoscopy for the diagnosis of nonpigmented cancers of the skin.pdf:pdf},
isbn = {0190-9622},
issn = {10976787},
journal = {Journal of the American Academy of Dermatology},
keywords = {dermatoscopy,dermoscopy,diagnosis,keratinocytic skin cancer,melanoma,nonpigmented skin cancer},
number = {6},
pages = {1100--1109},
pmid = {28941871},
publisher = {Elsevier Inc},
title = {{Accuracy of dermatoscopy for the diagnosis of nonpigmented cancers of the skin}},
url = {http://dx.doi.org/10.1016/j.jaad.2017.07.022},
volume = {77},
year = {2017}
}
@misc{Farberg2017a,
author = {Farberg, Aaron S. and Rigel, Darrell S.},
booktitle = {Dermatologic Clinics},
doi = {10.1016/j.det.2017.06.019},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Dermatologic Clinics/2017{\_}The Importance of Early Recognition of Skin Cancer.pdf:pdf},
isbn = {9780323546621},
issn = {15580520},
keywords = {Medicine},
mendeley-tags = {Medicine},
number = {4},
pages = {xv--xvi},
title = {{The Importance of Early Recognition of Skin Cancer}},
url = {http://linkinghub.elsevier.com/retrieve/pii/S0733863517300955},
volume = {35},
year = {2017}
}
@article{Pathan2018,
abstract = {Computerized image analysis methods for dermoscopy are primarily of great interest and benefit, as it provides significant information about the lesion, which can be of pertinence for the clinicians and a stand-alone warning implement. Computer-based diagnostic systems require dedicated image processing algorithms to provide mathematical descriptions of the suspected regions, such systems hold a great potential in oncology. In this paper, we have performed a review of the state of art techniques used in computer-aided diagnostic systems, by giving the domain aspects of melanoma followed by the prominent techniques used in each of the steps. The steps include dermoscopic image pre-processing, segmentation, extraction and selection of peculiar features, and relegation of skin lesions. The paper also presents cognizance to judge the consequentiality of every methodology utilized in the literature, in addition to the corresponding results obtained in this perspective. The inadequacies and the future research directions are accentuated.},
author = {Pathan, Sameena and Prabhu, K. Gopalakrishna and Siddalingaswamy, P. C.},
doi = {10.1016/j.bspc.2017.07.010},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Biomedical Signal Processing and Control/2018{\_}Techniques and algorithms for computer aided diagnosis of pigmented skin lesions—A review.pdf:pdf},
isbn = {1875-0362},
issn = {17468108},
journal = {Biomedical Signal Processing and Control},
keywords = {Acquisition,Classification,Dermoscopy,Melanoma,Pigmented skin lesions (PSLs),Segmentation},
pages = {237--262},
pmid = {618571949},
title = {{Techniques and algorithms for computer aided diagnosis of pigmented skin lesions—A review}},
volume = {39},
year = {2018}
}
@article{Cinotti2018,
abstract = {{\textcopyright} 2018 European Academy of Dermatology and Venereology Background: Several dermoscopic and in vivo reflectance confocal microscopy (RCM) diagnostic criteria of lentigo maligna (LM)/lentigo maligna melanoma (LMM) have been identified. However, no study compared the diagnostic accuracy of these techniques. Objective: We evaluated the diagnostic accuracy of dermoscopy and RCM for LM/LMM using a holistic assessment of the images. Methods: A total of 223 facial lesions were evaluated by 21 experts. Diagnostic accuracy of the clinical, dermoscopic and RCM examination was compared. Interinvestigator variability and confidence level in the diagnosis were also evaluated. Results: Overall diagnostic accuracy of the two imaging techniques was good (area under the curve of the sROC function: 0.89). RCM was more sensitive (80{\%}, vs. 61{\%}) and less specific (81{\%} vs. 92{\%}) than dermoscopy for LM/LMM. In particular, RCM showed a higher sensitivity for hypomelanotic and recurrent LM/LMM. RCM had a higher interinvestigator agreement and a higher confidence level in the diagnosis than dermoscopy. Conclusion: Reflectance confocal microscopy and dermoscopy are both useful techniques for the diagnosis of facial lesions and in particular LM/LMM. RCM is particularly suitable for the identification of hypomelanotic and recurrent LM/LMM.},
author = {Cinotti, E. and Labeille, B. and Debarbieux, S. and Carrera, C. and Lacarrubba, F. and Witkowski, A. M. and Moscarella, E. and Arzberger, E. and Kittler, H. and Bahadoran, P. and Gonzalez, S. and Guitera, P. and Agozzino, M. and Farnetani, F. and Hofmann-Wellenhof, R. and Ardig{\`{o}}, M. and Rubegni, P. and Tognetti, L. and {\L}udzik, J. and Zalaudek, I. and Argenziano, G. and Longo, C. and Ribero, S. and Malvehy, J. and Pellacani, G. and Cambazard, F. and Perrot, J. L.},
doi = {10.1111/jdv.14791},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of the European Academy of Dermatology and Venereology/2018{\_}Dermoscopy vs. reflectance confocal microscopy for the diagnosis of lentigo maligna.pdf:pdf},
issn = {14683083},
journal = {Journal of the European Academy of Dermatology and Venereology},
number = {8},
pages = {1284--1291},
pmid = {29341263},
title = {{Dermoscopy vs. reflectance confocal microscopy for the diagnosis of lentigo maligna}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/jdv.14791},
volume = {32},
year = {2018}
}
@article{Haralick1973,
abstract = {Texture is one of the important characteristics used in identifying objects or regions of interest in an image, whether the image be a photomicrograph, an aerial photograph, or a satellite image. This paper describes some easily computable texture features based on gray-tone spatial dependancies, and illustrates their application in category-identification tasks of three different kinds of image data: photomicrographs of five kinds of sandstones, 1:20 000 panchromatic aerial photographs of eight land-use categories, and Earth Resources Technology Satellite (ERTS) multispecial imagery containing seven land-use categories. We use two kinds of decision rules: one for which the decision regions are convex polyhedra (a piecewise linear decision rule), and one for which the decision regions are rectangular parallelpipeds (a min-max decision rule). In each experiment the data set was divided into two parts, a training set and a test set. Test set identification accuracy is 89{\%} for the photomicrogaphs, 82{\%} for the aerial photographic imagery and 83{\%} for the satellite imagery. These results indicate that the easily computable textural features probably have a general applicability for a wide variety of image-classification applications.},
author = {Haralick, Robert M. and Dinstein, Its'hak and Shanmugam, K.},
doi = {10.1109/TSMC.1973.4309314},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/IEEE Transactions on Systems, Man and Cybernetics/1973{\_}Textural Features for Image Classification.pdf:pdf},
issn = {0018-9472},
journal = {IEEE Transactions on Systems, Man and Cybernetics},
number = {6},
pages = {610--621},
title = {{Textural Features for Image Classification}},
volume = {SMC-3},
year = {1973}
}
@article{Cawley2010,
abstract = {Model selection strategies for machine learning algorithms typically involve$\backslash$nthe numerical optimisation of an appropriate model selection criterion, often$\backslash$nbased on an estimator of generalisation performance, such as k-fold $\backslash$ncross-validation. The error of such an estimator can be broken down into bias $\backslash$nand variance components. While unbiasedness is often cited as a beneficial $\backslash$nquality of a model selection criterion, we demonstrate that a low variance is $\backslash$nat least as important, as a non-negligible variance introduces the potential $\backslash$nfor over-fitting in model selection as well as in training the model. While $\backslash$nthis observation is in hindsight perhaps rather obvious, the degradation in $\backslash$nperformance due to over-fitting the model selection criterion can be $\backslash$nsurprisingly large, an observation that appears to have received little $\backslash$nattention in the machine learning literature to date. In this paper, we show $\backslash$nthat the effects of this form of over-fitting are often of comparable $\backslash$nmagnitude to differences in performance between learning algorithms, and thus $\backslash$ncannot be ignored in empirical evaluation. Furthermore, we show that some $\backslash$ncommon performance evaluation practices are susceptible to a form of selection $\backslash$nbias as a result of this form of over-fitting and hence are unreliable. We $\backslash$ndiscuss methods to avoid over-fitting in model selection and subsequent $\backslash$nselection bias in performance evaluation, which we hope will be incorporated $\backslash$ninto best practice. While this study concentrates on cross-validation based $\backslash$nmodel selection, the findings are quite general and apply to any model $\backslash$nselection practice involving the optimisation of a model selection criterion $\backslash$nevaluated over a finite sample of data, including maximisation of the Bayesian $\backslash$nevidence and optimisation of performance bounds.},
author = {Cawley, Gavin C. and Talbot, Nicola L.},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of Machine Learning Research/2010{\_}On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation.pdf:pdf},
issn = {1532-4435},
journal = {Journal of Machine Learning Research},
keywords = {bias-variance trade-off,model selection,over-,performance evaluation,selection bias},
pages = {2079--2107},
title = {{On Over-fitting in Model Selection and Subsequent Selection Bias in Performance Evaluation}},
url = {http://dl.acm.org/citation.cfm?id=1756006.1859921},
volume = {11},
year = {2010}
}
@article{Esteva2017,
abstract = {Skin cancer, the most common human malignancy, is primarily diagnosed visually, beginning with an initial clinical screening and followed potentially by dermoscopic analysis, a biopsy and histopathological examination. Automated classification of skin lesions using images is a challenging task owing to the fine-grained variability in the appearance of skin lesions. Deep convolutional neural networks (CNNs) show potential for general and highly variable tasks across many fine-grained object categories. Here we demonstrate classification of skin lesions using a single CNN, trained end-to-end from images directly, using only pixels and disease labels as inputs. We train a CNN using a dataset of 129,450 clinical images-two orders of magnitude larger than previous datasets-consisting of 2,032 different diseases. We test its performance against 21 board-certified dermatologists on biopsy-proven clinical images with two critical binary classification use cases: keratinocyte carcinomas versus benign seborrheic keratoses; and malignant melanomas versus benign nevi. The first case represents the identification of the most common cancers, the second represents the identification of the deadliest skin cancer. The CNN achieves performance on par with all tested experts across both tasks, demonstrating an artificial intelligence capable of classifying skin cancer with a level of competence comparable to dermatologists. Outfitted with deep neural networks, mobile devices can potentially extend the reach of dermatologists outside of the clinic. It is projected that 6.3 billion smartphone subscriptions will exist by the year 2021 (ref. 13) and can therefore potentially provide low-cost universal access to vital diagnostic care.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Esteva, Andre and Kuprel, Brett and Novoa, Roberto A. and Ko, Justin and Swetter, Susan M. and Blau, Helen M. and Thrun, Sebastian},
doi = {10.1038/nature21056},
eprint = {arXiv:1011.1669v3},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Nature/2017{\_}Dermatologist-level classification of skin cancer with deep neural networks.pdf:pdf},
isbn = {0028-0836},
issn = {14764687},
journal = {Nature},
number = {7639},
pages = {115--118},
pmid = {28117445},
title = {{Dermatologist-level classification of skin cancer with deep neural networks}},
volume = {542},
year = {2017}
}
@article{Koller2011,
abstract = {In vivo reflectance confocal microscopy (RCM) has been shown to be a valuable imaging tool in the diagnosis of melanocytic skin tumours. However, diagnostic image analysis performed by automated systems is to date quite rare.},
author = {Koller, S. and Wiltgen, M. and Ahlgrimm-Siess, V. and Weger, W. and Hofmann-Wellenhof, R. and Richtig, E. and Smolle, J. and Gerger, A.},
doi = {10.1111/j.1468-3083.2010.03834.x},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Journal of the European Academy of Dermatology and Venereology/2011{\_}In vivo reflectance confocal microscopy Automated diagnostic image analysis of melanocytic skin tumours.pdf:pdf},
issn = {1468-3083},
journal = {Journal of the European Academy of Dermatology and Venereology},
keywords = {image analysis,melanocytic skin tumours,reflectance confocal microscopy},
number = {5},
pages = {554--558},
pmid = {20735518},
title = {{In vivo reflectance confocal microscopy: Automated diagnostic image analysis of melanocytic skin tumours}},
volume = {25},
year = {2011}
}
@article{Gerger2006,
abstract = {BACKGROUND: Melanoma and nonmelanoma skin cancer are the most frequent malignant tumors by far among whites. Currently, early diagnosis is the most efficient method for preventing a fatal outcome. In vivo confocal laser-scanning microscopy (CLSM) is a recently developed potential diagnostic tool. METHODS: One hundred seventeen melanocytic skin lesions and 45 nonmelanocytic skin lesions (90 benign nevi, 27 malignant melanomas, 15 basal cell carcinomas, and 30 seborrheic keratoses) were sampled consecutively and were examined using proprietary CLSM equipment. Stored images were rated by 4 independent observers. RESULTS: Differentiation between melanoma and all other lesions based solely on CLSM examination was achieved with a positive predictive value of 94.22{\%}. Malignant lesions (melanoma and basal cell carcinoma) as a group were diagnosed with a positive predictive value of 96.34{\%}. Assessment of distinct CLSM features showed a strong interobserver correlation (kappa {\textgreater}0.80 for 11 of 13 criteria). Classification and regression tree analysis yielded a 3-step algorithm based on only 3 criteria, facilitating a correct classification in 96.30{\%} of melanomas, 98.89{\%} of benign nevi, and 100{\%} of basal cell carcinomas and seborrheic keratoses. CONCLUSIONS: In vivo CLSM examination appeared to be a promising method for the noninvasive assessment of melanoma and nonmelanoma skin tumors.},
author = {Gerger, Armin and Koller, Silvia and Weger, Wolfgang and Richtig, Erika and Kerl, Helmut and Samonigg, Hellmut and Krippl, Peter and Smolle, Josef},
doi = {10.1002/cncr.21910},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/Cancer/2006{\_}Sensitivity and specificity of confocal laser-scanning microscopy for in vivo diagnosis of malignant skin tumors.pdf:pdf},
isbn = {1097-0142},
issn = {0008543X},
journal = {Cancer},
keywords = {Basal cell carcinoma,Confocal laser-scanning microscopy,Malignant melanoma,Sensitivity,Specificity},
number = {1},
pages = {193--200},
pmid = {16615102},
title = {{Sensitivity and specificity of confocal laser-scanning microscopy for in vivo diagnosis of malignant skin tumors}},
volume = {107},
year = {2006}
}
@article{Guitera2009,
abstract = {We recently described an in vivo reflectance confocal microscopy (RCM) method and our aim was to evaluate a possible additive value of this type of analysis in the management of melanocytic lesions. In two referral centers (Sydney and Modena), lesions (203 nevi and 123 melanomas (MMs) with a median Breslow thickness of 0.54 mm) were excised on the basis of clinical suspicion (history, dermoscopy examination, and/or digital monitoring). The RCM method was also trialed on a non-biopsied population of 100 lesions, which were clinically and dermoscopically diagnosed as benign nevi. All RCM and dermoscopy diagnoses were performed blinded to the histopathological diagnosis. Firstly, in the study population, a high interobserver agreement (on a subset of 90 lesions) was seen with the RCM method, which had superior specificity (68{\%}, 95{\%} confidence interval (95{\%} CI): 61.1-74.3) for the diagnosis of MM compared with dermoscopy (32{\%}, 95{\%} CI: 25.9-38.7), while showing no difference in sensitivity (91{\%}, 95{\%} CI: 84.6-95.5, RCM; 88{\%}, 95{\%} CI: 80.7-92.6 dermoscopy). The two techniques had a weak correlation, resulting in only 2.4{\%} of MMs being misclassified by both techniques. Diagnosis of light-colored lesions is improved by RCM (specificity 84{\%}, 95{\%} CI: 66.3-94.5) compared with dermoscopy (specificity 39{\%}, 95{\%} CI: 23.7-56.2). Secondly, the RCM method classified 100{\%} of the non-biopsied control nevi population as benign.},
author = {Guitera, Pascale and Pellacani, Giovanni and Longo, Caterina and Seidenari, Stefania and Avramidis, Michelle and Menzies, Scott W.},
doi = {10.1038/jid.2008.193},
file = {:C$\backslash$:/Users/Romain/Documents/Bibliographie/PDF/The Journal of investigative dermatology/2009{\_}In vivo reflectance confocal microscopy enhances secondary evaluation of melanocytic lesions.pdf:pdf},
isbn = {0022-202X},
issn = {15231747},
journal = {The Journal of investigative dermatology},
number = {1},
pages = {131--138},
pmid = {18633444},
title = {{In vivo reflectance confocal microscopy enhances secondary evaluation of melanocytic lesions.}},
volume = {129},
year = {2009}
}
@INPROCEEDINGS{Hou2016, 
author={L. {Hou} and D. {Samaras} and T. M. {Kurc} and Y. {Gao} and J. E. {Davis} and J. H. {Saltz}}, 
booktitle={2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 
title={Patch-Based Convolutional Neural Network for Whole Slide Tissue Image Classification}, 
year={2016}, 
volume={}, 
number={}, 
pages={2424-2433}, 
keywords={cancer;image classification;learning (artificial intelligence);medical image processing;neural nets;optimisation;patch-based convolutional neural network;patch-based CNN;whole slide tissue image classification;WSI;CNN training;cancer subtype differentiation;cellular-level visual features;image patch scale;patch-level classifier;decision fusion model training;patch-level prediction aggregation;patch-level CNN;expectation-maximization based method;EM based method;discriminative patch automatic location;patch spatial relationships;glioma classification;nonsmall-cell lung carcinoma;Cancer;Training;Image resolution;Robustness;Predictive models;Neural networks;Visualization}, 
doi={10.1109/CVPR.2016.266}, 
ISSN={1063-6919}, 
month={June},}
@INPROCEEDINGS{Xu2015, 
author={Y. {Xu} and Z. {Jia} and Y. {Ai} and F. {Zhang} and M. {Lai} and E. I. {Chang}}, 
booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
title={Deep convolutional activation features for large scale Brain Tumor histopathology image classification and segmentation}, 
year={2015}, 
volume={}, 
number={}, 
pages={947-951}, 
keywords={brain;feature extraction;image classification;image segmentation;medical image processing;tumours;deep convolutional activation features;brain tumor histopathology;image classification;image segmentation;MICCAI 2014 Brain Tumor Digital Pathology Challenge;image dimensions;CNN activations;ImageNet;features extraction;Image segmentation;Feature extraction;Biomedical imaging;Tumors;Support vector machines;Training data;Training;deep convolutional activation features;deep learning;feature learning;segmentation;classification}, 
doi={10.1109/ICASSP.2015.7178109}, 
ISSN={1520-6149}, 
month={April},}